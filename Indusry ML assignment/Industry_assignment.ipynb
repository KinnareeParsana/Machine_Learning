{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Industry_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rku5IApPUKkb"
      },
      "source": [
        "#News paper categorization using Machine Learning models\n",
        "There are 4 categories in it which are:\n",
        "\n",
        "Politics: 0 \n",
        "\n",
        "Technology: 1 \n",
        "\n",
        "Entertainment:2 \n",
        "\n",
        "Business: 3\n",
        "\n",
        "There are 3 excels sheets given for categorization train, test and sample submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XgjKfkp1qxE"
      },
      "source": [
        "#importing basic libraries\n",
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUxEIQp_6KNz"
      },
      "source": [
        "from google.colab import drive #for mounting the google drive "
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxyoRscH6KZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcb9b32-ef28-429f-a9a8-4599ff9c8e74"
      },
      "source": [
        "#locating current working directory where our data is stored\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba16RkWb6Kba",
        "outputId": "e11eb89b-193d-4527-f873-4f1779984316"
      },
      "source": [
        "cd /content/drive/\"My Drive/Colab Notebooks/data1\""
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/data1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYflbS-x2DEI"
      },
      "source": [
        "#load data\n",
        "df_train = pd.read_excel('Data_Train.xlsx')\n",
        "df_test = pd.read_excel('Data_Test.xlsx')\n",
        "df_sample = pd.read_excel('Sample_submission.xlsx')"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mOBiS9yKVxFZ",
        "outputId": "402e2d05-3c15-4be4-a574-f4d0a2ff15d1"
      },
      "source": [
        "#print first 5 data from train excel\n",
        "df_train.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the most painful was the huge reversal in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How formidable is the opposition alliance amon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Most Asian currencies were trading lower today...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you want to answer any question, click on ‘...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In global markets, gold prices edged up today ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY  SECTION\n",
              "0  But the most painful was the huge reversal in ...        3\n",
              "1  How formidable is the opposition alliance amon...        0\n",
              "2  Most Asian currencies were trading lower today...        3\n",
              "3  If you want to answer any question, click on ‘...        1\n",
              "4  In global markets, gold prices edged up today ...        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PW7KfrmBWEnE",
        "outputId": "fe42cd4d-42dc-42b3-bc7c-e8e465c493bd"
      },
      "source": [
        "#print first 5 data from test excel\n",
        "df_test.head()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019 will see gadgets like gaming smartphones ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It has also unleashed a wave of changes in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It can be confusing to pick the right smartpho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mobile application is integrated with a da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We have rounded up some of the gadgets that sh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY\n",
              "0  2019 will see gadgets like gaming smartphones ...\n",
              "1  It has also unleashed a wave of changes in the...\n",
              "2  It can be confusing to pick the right smartpho...\n",
              "3  The mobile application is integrated with a da...\n",
              "4  We have rounded up some of the gadgets that sh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dXrnsYdEWJ0J",
        "outputId": "3e0073cc-f204-4433-81df-50a3e8e6ea42"
      },
      "source": [
        "#print first 5 data from submission example excel\n",
        "df_sample.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SECTION\n",
              "0        3\n",
              "1        3\n",
              "2        3\n",
              "3        3\n",
              "4        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUqrLpcYZN0Y"
      },
      "source": [
        "Data cleaning and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_3Qj_EA2Eun"
      },
      "source": [
        "#making function for removing noise from the data\n",
        "import re #regular expression library for combine a regular expression pattern into pattern objects, which is used for pattern matching.\n",
        "import itertools #worls like for loop it works ast as compare to for loop\n",
        "def cleanData(clean_data):\n",
        "    # Make all data in lowercase\n",
        "    clean_data = clean_data.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "    # Remove whitespaces from sentences\n",
        "    clean_data = clean_data.apply(lambda x: \" \".join(x.strip() for x in x.split()))\n",
        "    # Convert data to string\n",
        "    clean_data = clean_data.astype(str)\n",
        "    return clean_data"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICQuY8sPbvh9",
        "outputId": "d3f807fb-5355-48dc-d567-8afcce85ddd7"
      },
      "source": [
        "cleanData"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.cleanData>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWDlPmXV2JIZ"
      },
      "source": [
        "#cleanData called for removinf whitespace, noise, converting into lowercase and string\n",
        "df_train['STORY'] = cleanData(df_train['STORY'])\n",
        "df_test['STORY'] = cleanData(df_test['STORY'])\n",
        "#in sample data there is no story column so we don't need "
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLdGL2_IZt8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e978b913-13dd-40a4-8eaa-5f9b34129f21"
      },
      "source": [
        "df_train['STORY']"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       but the most painful was the huge reversal in ...\n",
              "1       how formidable is the opposition alliance amon...\n",
              "2       most asian currencies were trading lower today...\n",
              "3       if you want to answer any question, click on ‘...\n",
              "4       in global markets, gold prices edged up today ...\n",
              "                              ...                        \n",
              "7623    karnataka has been a congress bastion, but it ...\n",
              "7624    the film, which also features janhvi kapoor, w...\n",
              "7625    the database has been created after bringing t...\n",
              "7626    the state, which has had an uneasy relationshi...\n",
              "7627    virus stars kunchacko boban, tovino thomas, in...\n",
              "Name: STORY, Length: 7628, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W95rwqlZts0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e032d4-9312-4376-b824-64e4e1ee106f"
      },
      "source": [
        "df_test['STORY']"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2019 will see gadgets like gaming smartphones ...\n",
              "1       it has also unleashed a wave of changes in the...\n",
              "2       it can be confusing to pick the right smartpho...\n",
              "3       the mobile application is integrated with a da...\n",
              "4       we have rounded up some of the gadgets that sh...\n",
              "                              ...                        \n",
              "2743    according to researchers, fraud in the mobile ...\n",
              "2744    the iphone xs and xs max share the apple a12 c...\n",
              "2745    on the photography front, the note 5 pro featu...\n",
              "2746    uday mandated that discoms bring the gap betwe...\n",
              "2747    ripple also helps bank customers send money to...\n",
              "Name: STORY, Length: 2748, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUbyd-WsaVb7"
      },
      "source": [
        "Extracting features from data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leoEo9nO2JFa",
        "outputId": "5665ee3d-1d9b-41bf-e922-1ec6830d1af6"
      },
      "source": [
        "#for feature extraction we can use tokenization to splitting up a long text into smaller lines/words then we can use, \n",
        "from nltk.tokenize import WordPunctTokenizer # wordPunctTokenizer for extract the tokens from string of words or sentences in the form of alphabetic or nonalphabetic. then,\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # we are converting our collection of raw documents to a matrix of TF-IDF features.\n",
        "from sklearn.feature_extraction.text import CountVectorizer # we are transforming a given text into a vector on the basis of the frequency word in text. It is like sparse matrix.\n",
        "\n",
        "wpt = WordPunctTokenizer() #first we toknizing text\n",
        "cv = CountVectorizer(tokenizer=wpt.tokenize, stop_words='english', ngram_range=(1,3))#converting to vector\n",
        "\n",
        "cv.fit(df_train.STORY.tolist() + df_test.STORY.tolist()) \n",
        "df_train_cv = cv.transform(df_train.STORY) #transformig it onto train story\n",
        "df_test_cv = cv.transform(df_test.STORY) #transformig it onto test story"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMvpBp62pqcB",
        "outputId": "23986fd5-2545-4061-962c-728336265f35"
      },
      "source": [
        "df_train_cv,df_test_cv"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<7628x1039447 sparse matrix of type '<class 'numpy.int64'>'\n",
              " \twith 1575005 stored elements in Compressed Sparse Row format>,\n",
              " <2748x1039447 sparse matrix of type '<class 'numpy.int64'>'\n",
              " \twith 554993 stored elements in Compressed Sparse Row format>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_07gwsh2I6c"
      },
      "source": [
        "#vectorizing \n",
        "tf_vector = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',ngram_range=(1, 3), use_idf=1.0,smooth_idf=1.0,sublinear_tf=1.0,stop_words = 'english')\n",
        "\n",
        "tf_vector.fit(df_train.STORY.tolist() + df_test.STORY.tolist())\n",
        "df_train_tfv = tf_vector.transform(df_train.STORY)\n",
        "df_test_tfv = tf_vector.transform(df_test.STORY)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXPN4O1Qbyea"
      },
      "source": [
        "Train model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU88YTb02euo"
      },
      "source": [
        "#we are using Logistic regression mltiple for categoring classificaton.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats.mstats import mode"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFdJw2fW2i_8",
        "outputId": "08f1bb13-c5a5-41a9-f676-a9fb175a1f62"
      },
      "source": [
        "#traing using logistic regression \n",
        "training = {'C': 0.9, 'max_iter': 50, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
        "lr = LogisticRegression(**training, class_weight='balanced')\n",
        "lr.fit(df_train_cv, df_train.SECTION)\n",
        "\n",
        "training = {'C': 250, 'max_iter': 50, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
        "lr2 = LogisticRegression(**training, class_weight='balanced')\n",
        "lr2.fit(df_train_tfv, df_train.SECTION)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=250, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=50, multi_class='ovr', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzQDba3Fltap"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Iumrp72ob6"
      },
      "source": [
        "#testing\n",
        "lrprediction = lr.predict_proba(df_test_cv)\n",
        "lrprediction2 = lr2.predict_proba(df_test_tfv)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRCAPq3NgGNC",
        "outputId": "0234e092-e148-4303-e1c3-cbad0087eb09"
      },
      "source": [
        "#printing predicted matrix\n",
        "lrprediction,lrprediction2"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.23078009e-08, 9.99999986e-01, 1.50451005e-23, 1.72219540e-09],\n",
              "        [2.21357423e-02, 5.61302334e-02, 9.11061608e-01, 1.06724159e-02],\n",
              "        [3.79080507e-08, 9.99999921e-01, 2.62461756e-21, 4.09313654e-08],\n",
              "        ...,\n",
              "        [5.13555352e-05, 9.99131674e-01, 6.09595632e-06, 8.10874304e-04],\n",
              "        [4.60826754e-01, 5.08758417e-03, 1.56772942e-21, 5.34085662e-01],\n",
              "        [4.40303405e-03, 9.50898942e-01, 1.96483330e-06, 4.46960592e-02]]),\n",
              " array([[2.78204123e-05, 9.99961526e-01, 7.39826033e-06, 3.25581245e-06],\n",
              "        [1.02607302e-02, 3.97042374e-02, 9.48743713e-01, 1.29131915e-03],\n",
              "        [3.38682378e-05, 9.99884766e-01, 1.84351271e-05, 6.29307546e-05],\n",
              "        ...,\n",
              "        [6.71655050e-04, 9.95523082e-01, 1.50450782e-03, 2.30075490e-03],\n",
              "        [6.94091411e-01, 1.24683122e-02, 1.21774381e-04, 2.93318502e-01],\n",
              "        [1.05712878e-03, 9.71733421e-01, 1.43403912e-03, 2.57754108e-02]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EFZASP2Ggf4I",
        "outputId": "2297857a-dde1-41ab-e88f-2b82c7dbc0cf"
      },
      "source": [
        "#making predictions and save output in excel file\n",
        "lrtest = np.mean([lrprediction, lrprediction2], axis=0)\n",
        "lrpred = np.argmax(lrtest, axis=1)\n",
        "df = pd.DataFrame()\n",
        "df['SECTION'] = lrpred.astype(int)\n",
        "df.to_excel(\"lrpred.xlsx\", index=None)\n",
        "df.head(10)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SECTION\n",
              "0        1\n",
              "1        2\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "5        1\n",
              "6        1\n",
              "7        2\n",
              "8        1\n",
              "9        2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    }
  ]
}